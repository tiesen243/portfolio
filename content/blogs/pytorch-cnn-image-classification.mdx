---
title: 'Build Your Own Image Classifier: A CNN Journey with PyTorch'
description: Dive into the world of Convolutional Neural Networks (CNNs) by building your own image classifier using PyTorch. This blog explores the steps involved, referencing the tiesen243/cnn repository on GitHub.
publishedAt: 2024-10-27
tags:
  - CNN
  - PyTorch
  - Image Classification
  - Deep Learning
---

## Introduction

Convolutional Neural Networks (CNNs) are a powerful type of deep learning architecture that excel at image recognition and classification tasks. In this blog, we'll embark on a hands-on journey to build a CNN model using PyTorch, a popular deep learning framework.

We'll be referencing the [tiesen243/cnn](https://github.com/tiesen243/cnn.git) repository on GitHub as a guide. This repository provides a basic framework for building a CNN model, allowing us to understand the core concepts without getting bogged down in complex details.

## Getting Started

### Prerequisites

Before we dive into building our image classifier, make sure you have the following prerequisites installed on your system:

- Anaconda or Miniconda
- Nvidia GPU (optional but recommended for faster training) with CUDA support. You can check if your GPU has CUDA support by running `nvidia-smi` in the terminal.

### Setting Up the Environment

To get started, we'll create a new conda environment with packages from the `environment.yml` file provided in the repository. Run the following commands in your terminal:

```bash
conda env create -f environment.yml
conda activate ml
```

This will set up a new conda environment named `ml` with all the necessary packages for our project.

### Dataset Preparation

For this project, we'll be using the MNIST dataset, a popular dataset of handwritten digits from pytorch torchvision. The dataset consists of 60,000 training images and 10,000 test images.

![MNIST Dataset](/assets/blog/cnn-mnist.png)

We can load the MNIST dataset using PyTorch's `torchvision` library and create data loaders for training and testing as follows:

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

preprocess = transforms.Compose(
    [
        transforms.ToTensor(),
        transforms.Normalize((0.5,), (0.5,)),
    ]
)

train_set = datasets.MNIST(
    root="./data", train=True, download=True, transform=preprocess
)
test_set = datasets.MNIST(
    root="./data", train=False, download=True, transform=preprocess
)

train_loader = DataLoader(train_set, batch_size=64, shuffle=True)
test_loader = DataLoader(test_set, batch_size=64, shuffle=False)
```

## Building the CNN Model

Now that we have our dataset ready, let's build our CNN model. We'll define a simple CNN architecture with two convolutional layers followed by two fully connected layers. Here's the code snippet for building the model:

1. Import the necessary libraries:

```python
import torch
import matplotlib.pyplot as plt

from tqdm import tqdm
from torch import nn, optim
from torchsummary import summary
from torch.utils.data import DataLoader, random_split
```

2. Check if CUDA is available and set the device accordingly:

```python
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
```

3. Define the CNN model architecture:

```python
class CNN(nn.Module):
    def __init__(self, layers: list[nn.Module]):
        super().__init__()
        self.history = []
        self.layers = nn.ModuleList(layers)
        self.to(device)

    def add(self, layer: nn.Module):
        self.layers.append(layer)

    def summary(self, input_shape, batch_size):
        summary(self, input_shape, batch_size)
```

In this `__init__` method, we define the layers of our CNN model and move the model to the GPU if CUDA is available.

- `history` is used to store the training history of the model.
- `layers` is a list of layers in the model, initialized as an empty list.

And `add` method allows us to add layers to the model dynamically.
Finally, the `summary` method provides a summary of the model architecture. For example, we can call `model.summary((1, 28, 28), 64)` to get a summary of the model with input shape `(1, 28, 28)` and batch size `64`.

```text
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [64, 32, 28, 28]             320
              ReLU-2           [64, 32, 28, 28]               0
            Conv2d-3           [64, 64, 28, 28]          18,496
              ReLU-4           [64, 64, 28, 28]               0
         MaxPool2d-5           [64, 64, 14, 14]               0
           Flatten-6                [64, 12544]               0
            Linear-7                  [64, 128]       1,605,760
              ReLU-8                  [64, 128]               0
            Linear-9                   [64, 10]           1,290
          Softmax-10                   [64, 10]               0
================================================================
Total params: 1,625,866
Trainable params: 1,625,866
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.19
Forward/backward pass size (MB): 85.88
Params size (MB): 6.20
Estimated Total Size (MB): 92.28
----------------------------------------------------------------
```

4. Define the forward pass method:

```python title="class CNN(nn.Module)"
def forward(self, x):
    for layer in self.layers:
        x = layer(x)
    return x
```

In this method, we pass the input `x` through each layer of the model sequentially to get the final output. This is the core functionality of our CNN model.

5. Define the configuration for the CNN model:

```python title="class CNN(nn.Module)"
def config(self, loss: nn.Module, optimizer: optim.Optimizer):
    if not isinstance(loss, nn.Module):
        raise TypeError("loss must be a torch.nn.Module instance")
    if not isinstance(optimizer, optim.Optimizer):
        raise TypeError("optimizer must be a torch.optim.Optimizer instance")

    self.criterion = loss
    self.optimizer = optimizer
```

This method allows us to configure the loss function and optimizer for our model. We can set the loss function and optimizer using this method before training the model.

- `loss` is the loss function used for training the model (e.g., CrossEntropyLoss, MSELoss). For classification tasks, we typically use `nn.CrossEntropyLoss`.
- `optimizer` is the optimization algorithm used to update the model parameters during training (e.g., SGD, Adam). We can set the optimizer using this method. For example, `model.config(nn.CrossEntropyLoss(), optim.Adam(model.parameters(), lr=0.001))`.

6. Define the training loop:

```python title="class CNN(nn.Module)"
def fit(self, train_loader: DataLoader, epochs: int = 10, verbose: bool = True):
    for epoch in range(epochs):
        self.train()

        # Split the train set into train and validation set
        train_set, val_set = random_split(train_loader.dataset, [50000, 10000])
        train_set = DataLoader(train_set, batch_size=64, shuffle=True)
        val_set = DataLoader(val_set, batch_size=64, shuffle=True)

        loss_list = []

        for images, labels in tqdm(train_set, desc=f"Epoch {epoch+1}/{epochs}"):
            images, labels = images.to(device), labels.to(device)

            self.optimizer.zero_grad()

            outputs = self(images)
            loss = self.criterion(outputs, labels)
            loss_list.append(loss.item())

            loss.backward()
            self.optimizer.step()

        with torch.no_grad():
            self.eval()

            total = 0
            accuracy = 0
            val_loss = []

            for images, labels in val_set:
                images, labels = images.to(device), labels.to(device)

                outputs = self(images)
                total += labels.size(0)
                predicted = torch.argmax(outputs, dim=1)

                accuracy += (predicted == labels).sum().item()
                val_loss.append(self.criterion(outputs, labels).item())

            # Calculate the mean loss and accuracy
            mean_val_loss = sum(val_loss) / len(val_loss)
            mean_val_acc = 100 * (accuracy / total)
            loss = sum(loss_list) / len(loss_list)
            self.history.append((loss, mean_val_loss, mean_val_acc))

            if verbose:
                print(
                    f"Loss: {loss:.4f}, Val Loss: {mean_val_loss:.4f}, Val Accuracy: {mean_val_acc:.2f}%"
                )

    return self.history
```

This method trains the model on the training set for a specified number of epochs. It also calculates the validation loss and accuracy after each epoch.

In each epoch, we iterate over the training set, compute the loss, backpropagate the gradients, and update the model parameters using the optimizer. We also evaluate the model on the validation set to monitor its performance.

First, we set the model to training mode using `self.train()`. Then, we split the training set into a new training set and a validation set using `random_split`. We create new data loaders for the training and validation sets.

Next, we iterate over the training set using `tqdm` to display a progress bar. We move the images and labels to the GPU if available. We zero out the gradients using `self.optimizer.zero_grad()`.

We pass the images through the model to get the outputs and calculate the loss using the specified loss function. We append the loss to the `loss_list` for tracking.

We backpropagate the loss and update the model parameters using `self.optimizer.step()`.

After training, we evaluate the model on the validation set. We calculate the validation loss and accuracy by comparing the predicted labels with the ground truth labels.

Finally, we calculate the mean loss and accuracy for the epoch and store them in the `self.history` list. We print the loss, validation loss, and validation accuracy if `verbose` is set to `True`.

The method returns the training history, which contains the training loss, validation loss, and validation accuracy for each epoch.

7. Define the prediction method:

```python title="class CNN(nn.Module)"
def predict(self, x):
    predicted = []

    with torch.no_grad():
        self.eval()
        for images, _ in x:
            images = images.to(device)

            outputs = self(images)
            predicted.append(torch.argmax(outputs, 1))

    return predicted
```

This method allows us to make predictions using the trained model. We pass a batch of images through the model and return the predicted labels.

8. Putting It All Together:

```python
class CNN(nn.Module):
    def __init__(self, layers: list[nn.Module]):
        super().__init__()
        self.history = []
        self.layers = nn.ModuleList(layers)
        self.to(device)

    def add(self, layer: nn.Module):
        self.layers.append(layer)

    def forward(self, x: torch.Tensor):
        for layer in self.layers:
            x = layer(x)

        return x

    def summary(self, input_shape, batch_size):
        summary(self, input_shape, batch_size)

    def config(self, loss: nn.Module, optimizer: optim.Optimizer):
        if not isinstance(loss, nn.Module):
            raise TypeError("loss must be a torch.nn.Module instance")
        if not isinstance(optimizer, optim.Optimizer):
            raise TypeError("optimizer must be a torch.optim.Optimizer instance")

        self.criterion = loss
        self.optimizer = optimizer

    def fit(self, train_loader: DataLoader, epochs: int = 10, verbose: bool = True):
        for epoch in range(epochs):
            self.train()

            # Split the train set into train and validation set
            train_set, val_set = random_split(train_loader.dataset, [50000, 10000])
            train_set = DataLoader(train_set, batch_size=64, shuffle=True)
            val_set = DataLoader(val_set, batch_size=64, shuffle=True)

            loss_list = []

            for images, labels in tqdm(train_set, desc=f"Epoch {epoch+1}/{epochs}"):
                images, labels = images.to(device), labels.to(device)

                self.optimizer.zero_grad()

                outputs = self(images)
                loss = self.criterion(outputs, labels)
                loss_list.append(loss.item())

                loss.backward()
                self.optimizer.step()

            with torch.no_grad():
                self.eval()

                total = 0
                accuracy = 0
                val_loss = []

                for images, labels in val_set:
                    images, labels = images.to(device), labels.to(device)

                    outputs = self(images)
                    total += labels.size(0)
                    predicted = torch.argmax(outputs, dim=1)

                    accuracy += (predicted == labels).sum().item()
                    val_loss.append(self.criterion(outputs, labels).item())

                # Calculate the mean loss and accuracy
                mean_val_loss = sum(val_loss) / len(val_loss)
                mean_val_acc = 100 * (accuracy / total)
                loss = sum(loss_list) / len(loss_list)
                self.history.append((loss, mean_val_loss, mean_val_acc))

                if verbose:
                    print(
                        f"Loss: {loss:.4f}, Val Loss: {mean_val_loss:.4f}, Val Accuracy: {mean_val_acc:.2f}%"
                    )

        return self.history

    def predict(self, x):
        predicted = []

        with torch.no_grad():
            self.eval()
            for images, _ in x:
                images = images.to(device)

                outputs = self(images)
                predicted.append(torch.argmax(outputs, 1))

        return predicted
```

## Training the Model

Now that we have defined our CNN model, we can train it on the MNIST dataset. Here's how you can train the model:

```python title="Define layers for the CNN model"
model = CNN(
    [
        nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),
        nn.ReLU(),
        nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2, stride=2, padding=0),
        nn.Flatten(),
        nn.Linear(64 * 14 * 14, 128),
        nn.ReLU(),
        nn.Linear(128, 10),
        nn.Softmax(dim=1),
    ]
)

model.summary(train_loader.dataset[0][0].shape, train_loader.batch_size)
```

This code snippet defines the layers for the CNN model. We use two convolutional layers followed by ReLU activation functions, max-pooling, and fully connected layers. The model architecture is summarized using the `summary` method.

- The first convolutional layer has 1 input channel, 32 output channels, a kernel size of 3, and padding of 1.
- The second convolutional layer has 32 input channels, 64 output channels, a kernel size of 3, and padding of 1.
- The max-pooling layer has a kernel size of 2 and a stride of 2.
- The first fully connected layer has 64 _ 14 _ 14 input features and 128 output features.
- The second fully connected layer has 128 input features and 10 output features (corresponding to the 10 classes in the MNIST dataset).
- The softmax layer is used to compute the class probabilities.

Next, we configure the model with the loss function and optimizer:

```python title="Configure the model"
model.config(nn.CrossEntropyLoss(), optim.Adam(model.parameters(), lr=0.001))
```

We use the `CrossEntropyLoss` as the loss function and the `Adam` optimizer with a learning rate of 0.001.

Finally, we train the model on the MNIST dataset:

```python title="Train the model"
history = model.fit(train_loader, epochs=10)
```

This code snippet trains the model on the training set for 10 epochs. The training loop prints the training loss, validation loss, and validation accuracy after each epoch.

Results:

```text
Epoch 1/10: 100%|██████████| 782/782 [00:05<00:00, 137.83it/s]
Loss: 1.6583, Val Loss: 1.4880, Val Accuracy: 97.40%
Epoch 2/10: 100%|██████████| 782/782 [00:05<00:00, 140.73it/s]
Loss: 1.4849, Val Loss: 1.4832, Val Accuracy: 97.85%
Epoch 3/10: 100%|██████████| 782/782 [00:05<00:00, 132.55it/s]
Loss: 1.4787, Val Loss: 1.4797, Val Accuracy: 98.15%
Epoch 4/10: 100%|██████████| 782/782 [00:05<00:00, 142.57it/s]
Loss: 1.4766, Val Loss: 1.4770, Val Accuracy: 98.45%
Epoch 5/10: 100%|██████████| 782/782 [00:05<00:00, 135.03it/s]
Loss: 1.4744, Val Loss: 1.4749, Val Accuracy: 98.62%
Epoch 6/10: 100%|██████████| 782/782 [00:05<00:00, 142.32it/s]
Loss: 1.4734, Val Loss: 1.4752, Val Accuracy: 98.59%
Epoch 7/10: 100%|██████████| 782/782 [00:05<00:00, 148.41it/s]
Loss: 1.4723, Val Loss: 1.4731, Val Accuracy: 98.84%
Epoch 8/10: 100%|██████████| 782/782 [00:05<00:00, 139.67it/s]
Loss: 1.4717, Val Loss: 1.4701, Val Accuracy: 99.11%
Epoch 9/10: 100%|██████████| 782/782 [00:05<00:00, 134.47it/s]
Loss: 1.4712, Val Loss: 1.4710, Val Accuracy: 99.03%
Epoch 10/10: 100%|██████████| 782/782 [00:05<00:00, 138.27it/s]
Loss: 1.4702, Val Loss: 1.4725, Val Accuracy: 98.90%
```

And yeah, you can see. This model just needs 2-3 epochs to reach 98% accuracy. I used 10 epochs to make the output more readable. You can try with fewer epochs to fasten the training process.

Then, you can plot the training history to visualize the training and validation loss and accuracy:

```python title="Plot the training history"
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.plot([x[0] for x in history], label="Train Loss")
plt.plot([x[1] for x in history], label="Val Loss")
plt.xlabel("Epoch")
plt.legend()
plt.subplot(1, 2, 2)
plt.plot([x[2] for x in history], label="Val Accuracy")
plt.xlabel("Epoch")
plt.legend()
plt.show()
```

This code snippet plots the training and validation loss on the left and the validation accuracy on the right. You can visualize how the model performs during training.

![Training History](/assets/blog/cnn-plot.png)

## Testing the Model

After training the model, we can evaluate its performance on the test set. Here's how you can test the model:

```python
x = [images for images, _ in test_loader]
y_true = [labels for _, labels in test_loader]
y_pred = model.predict(test_loader)
```

This code snippet gets the images and labels from the test loader and makes predictions using the trained model. We compare the predicted labels with the ground truth labels to evaluate the model's performance.

Next, we calculate the accuracy of the model on the test set:

```python
total = 0
correct = 0

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

for true, pred in zip(y_true, y_pred):
    true, pred = true.to(device), pred.to(device)
    total += len(true)
    correct += (true == pred).sum().item()

accuracy = 100 * (correct / total)
print(f"Test Accuracy: {accuracy:.2f}%") # Test Accuracy: 98.58%
```

Finally, we plot a random selection of test images along with their true and predicted labels:

```python
_, axs = plt.subplots(2, 5, figsize=(15, 6))

for i in range(10):
    random_idx = torch.randint(0, 64, (1, 2)).squeeze()
    axs[i // 5, i % 5].imshow(x[random_idx[0]][random_idx[1]].squeeze(), cmap="gray")
    color = "green" if y_true[random_idx[0]][random_idx[1]] == y_pred[random_idx[0]][random_idx[1]] else "red"
    axs[i // 5, i % 5].set_title(
        f"True: {y_true[random_idx[0]][random_idx[1]]}, Pred: {y_pred[random_idx[0]][random_idx[1]]}",
        color=color,
    )
    axs[i // 5, i % 5].axis("off")

plt.show()
```

This code snippet plots a grid of 10 test images along with their true and predicted labels. The true labels are displayed in green, while the incorrect predictions are displayed in red.

![Test Images](/assets/blog/cnn-test.png)

## Save and Load the Model

You can save the trained model to a file and load it later for inference. Here's how you can save and load the model:

```python
torch.save(model.state_dict(), "mnist_cnn.pth")
```

This code snippet saves the model's state dictionary to a file named `mnist_cnn.pth`.

To load the model for inference, you can use the following code:

```python
model = CNN(
    [
        nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),
        nn.ReLU(),
        nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2, stride=2, padding=0),
        nn.Flatten(),
        nn.Linear(64 * 14 * 14, 128),
        nn.ReLU(),
        nn.Linear(128, 10),
        nn.Softmax(dim=1),
    ]
)
model.load_state_dict(load("mnist_cnn.pth", weights_only=True))
model.eval()
```

This code snippet loads the model architecture and the trained weights from the file `mnist_cnn.pth`. The model is then set to evaluation mode for inference.

## Web UI for Image Classification

You can create a simple web UI to interact with the image classifier. Here's a basic example using Flask:

```python title="web.py"
import io
import flask
import base64
import flask_cors

from PIL import Image
from torch import nn, load
from torchvision import transforms

# Load the model
# Following the previous code snippet to load the model

# Initialize the Flask app
app = flask.Flask(__name__)
flask_cors.CORS(app)
current_image = None

# Define the image preprocessing pipeline using torchvision.transforms
def preprocess_image(image):
    # Define the image preprocessing pipeline
    preprocess = transforms.Compose(
        [
            transforms.ToTensor(),
            transforms.Normalize((0.5,), (0.5,)),
        ]
    )

    # Open the image using PIL
    image = Image.open(io.BytesIO(image))

    # convert image to base64 and store it in the global variable
    global current_image
    buffered = io.BytesIO()
    image.save(buffered, format="PNG")
    current_image = base64.b64encode(buffered.getvalue()).decode("utf-8")

    # Preprocess the image
    return preprocess(image).unsqueeze(0)

# Define the prediction route
@app.route("/predict", methods=["POST"])
def predict():
    image = flask.request.files.get("file")
    if image is None:
        return flask.redirect(flask.url_for("index"))

    image = preprocess_image(image.read()).to("cuda")
    prediction = model(image).argmax().item()

    return flask.redirect(flask.url_for("index", prediction=prediction))

# Define the index route
@app.route("/", methods=["GET"])
def index():
    prediction = flask.request.args.get("prediction") or ""
    global current_image

    return f"""
    <!doctype html>
    <html lang=en>
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <script src="https://cdn.tailwindcss.com"></script>
            <title>CNN MNIST</title>
        </head>
        <body class="bg-black text-white min-h-dvh grid place-items-center">
            <main class="container mx-auto flex flex-col gap-4 max-w-screen-md">
                <h1 class="scroll-m-20 text-4xl font-extrabold tracking-tight lg:text-5xl">Upload new File for Prediction</h1>

                <form method=post enctype=multipart/form-data action=predict class="flex gap-4 items-center">
                    <input type=file name=image class="flex h-10 w-full rounded-md border border-gray-500 bg-black px-3 py-2 text-sm ring-offset-black file:border-0 file:bg-transparent file:text-sm file:font-medium file:text-white placeholder:text-gray-500 focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-white focus-visible:ring-offset-2 disabled:cursor-not-allowed disabled:opacity-50">
                    <button class="h-10 px-4 py-2 inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium bg-white text-black hover:bg-white/90 ring-offset-black transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-white focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 [&_svg]:pointer-events-none [&_svg]:size-4 [&_svg]:shrink-0">
                        Upload
                    </button>
                </form>

                <div class="grid grid-cols-2 gap-4 place-items-center">
                    {current_image and f"""
                    <img src="data:image/png;base64,{current_image}" class="border border-white w-full rounded-lg" alt="Current Image">
                    """ or ""}
                    <h2 class="scroll-m-20 pb-2 text-3xl font-semibold tracking-tight first:mt-0 {current_image and "" or "col-start-2"}">Prediction: {prediction}</h2>
                </div>
            </main>
        </body>
    </html>
"""

# Run the Flask app
def main():
    app.run()

if __name__ == "__main__":
    main()
```

This code snippet defines a simple Flask app with two routes: `/` for the index page and `/predict` for making predictions. The index page allows users to upload an image for classification, and the prediction route processes the uploaded image and returns the predicted class.

You can run the Flask app by executing the following command in your terminal:

```bash
python web.py
```

This will start the Flask app, and you can access it in your browser at `http://localhost:5000`.

> Note: you can download test images from Kaggle: [MNIST as JPG](https://www.kaggle.com/scolianni/mnistasjpg)

![Web UI](/assets/blog/cnn-web.png)

## Conclusion

In this blog, we've explored the process of building a Convolutional Neural Network (CNN) image classifier using PyTorch. We've covered the steps involved in defining the CNN model, training it on the MNIST dataset, and evaluating its performance on the test set.

We've also demonstrated how to save and load the trained model for future use and create a simple web UI for interacting with the image classifier.

I hope this blog has provided you with a solid foundation for building your own image classifier using CNNs and PyTorch. Feel free to experiment with different model architectures, datasets, and hyperparameters to further enhance your understanding of CNNs and deep learning.

For more details, you can refer to the [tiesen243/cnn](https://github.com/tiesen243/cnn.git) repository on GitHub.
